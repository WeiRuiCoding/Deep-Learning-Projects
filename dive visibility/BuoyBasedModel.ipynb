{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buoy Based Model- Point Conception Transmitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.structured import *\n",
    "from fastai.column_data import *\n",
    "from fasterai.files import *\n",
    "from fasterai.structured import *\n",
    "from pathlib import Path\n",
    "from itertools import repeat\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "np.set_printoptions(threshold=50, edgeitems=20)\n",
    "PATH=Path('data/divevis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObsTableInfo():\n",
    "    def __init__(self, path: Path):\n",
    "        self.table = pd.read_csv(path, low_memory=False)\n",
    "        self.station = path.stem\n",
    "        self.year = path.parent.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load Raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "obs_table_paths = find_files_recursively(PATH/'obs', ('csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "obs_tables_infos = [ObsTableInfo(Path(path)) for path in obs_table_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The following returns summarized aggregate information to each table accross each field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning / Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a structured data problem, we necessarily have to go through all the cleaning and feature engineering, even though we're using a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Unecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_drop_columns=['AA1','AA2','AA3','AB1','AD1','AE1','AH1','AH2','AH3','AH4','AH5','AH6','AI1','AI2','AI3','AI4','AI5','AI6',\n",
    "         'AJ1','AK1','AM1','AN1','AT1','AT2','AT3','AT4','AU1','AU2','AU3','AW1','AW2','AW3','AX1','GA1','GA2','GA3','GD1',\n",
    "         'GD2','GD3','GF1','KA1','KA2','KB1','KB2','KB3','KC1','KC2','KD1','KD2','KE1','KG1','KG2','MA1','MD1','MF1',\n",
    "         'MG1','MH1','MK1','MV1','MW1','MW2','MW3','OC1','OD1','OE1','OE2','OE3','RH1','RH2','RH3','EQD','QUALITY_CONTROL',\n",
    "         'CALL_SIGN','REPORT_TYPE','NAME','ELEVATION','LONGITUDE','LATITUDE','SOURCE', 'SLP', 'VIS','TMP', 'CIG','DEW']\n",
    "\n",
    "for table_info in obs_tables_infos:\n",
    "    table = table_info.table\n",
    "    table.drop(columns=obs_drop_columns,inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Dates/Times for Later Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_info in obs_tables_infos:\n",
    "    table = table_info.table\n",
    "    name='DATE'\n",
    "    table[name]=pd.to_datetime(table[name])\n",
    "    table[name] = table[name].apply(lambda dt: datetime.datetime(dt.year, dt.month, dt.day, dt.hour, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Rid of Non-Metar Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_info in obs_tables_infos:\n",
    "    table = table_info.table\n",
    "    table = table[table['REM'].notnull()]\n",
    "    table = table[table['REM'].notna()]\n",
    "    table = table[table['REM'].str.startswith('MET')]\n",
    "    table_info.table=table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decompose Wind into Separate Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MET09701/04/12 13:54:02 METAR KBFL 042154Z 33010KT 5SM HZ CLR 21/06 A3026 RMK AO2 SLP244 T02110061 (RN)\n",
    "wnd_pat = re.compile(r'(.*?\\s+)(\\d{3})(\\d{2})(KT\\s+.*?)', re.IGNORECASE)\n",
    "\n",
    "for table_info in obs_tables_infos:\n",
    "    table = table_info.table\n",
    "    source='REM'\n",
    "    table['WND_DIR'] = table[source].apply(lambda wnd: wnd_pat.match(str(wnd)).group(2) if wnd_pat.match(str(wnd)) is not None else 999)\n",
    "    table['WND_SP'] = table[source].apply(lambda wnd: wnd_pat.match(str(wnd)).group(3) if wnd_pat.match(str(wnd)) is not None else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Temperatures/Dew Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dew_pat = re.compile(r'(.*?\\s+)(\\d{2})(/)(\\d{2})(\\s+.*?)', re.IGNORECASE)\n",
    "\n",
    "for table_info in obs_tables_infos:\n",
    "    table = table_info.table\n",
    "    source='REM'\n",
    "    table['TMP'] = table[source].apply(lambda temp_dew: temp_dew_pat.match(str(temp_dew)).group(2) if temp_dew_pat.match(str(temp_dew)) is not None else 99)\n",
    "    table['DEW'] = table[source].apply(lambda temp_dew: temp_dew_pat.match(str(temp_dew)).group(4) if temp_dew_pat.match(str(temp_dew)) is not None else 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Sea Level Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "slp_pat = re.compile(r'(.*?\\s+)(SLP)(\\d+)(\\s+.*?)', re.IGNORECASE)\n",
    "\n",
    "for table_info in obs_tables_infos:\n",
    "    table = table_info.table\n",
    "    source='REM'\n",
    "    table['SLP'] = table[source].apply(lambda slp: slp_pat.match(str(slp)).group(3) if slp_pat.match(str(slp)) is not None else 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_pat = re.compile(r'(.*?\\s+)(\\d+)(SM)(\\s+.*?)', re.IGNORECASE)\n",
    "for table_info in obs_tables_infos:\n",
    "    table = table_info.table\n",
    "    source='REM'\n",
    "    table_info.table['VIS'] = table[source].apply(lambda vis: vis_pat.match(str(vis)).group(2) if vis_pat.match(str(vis)) is not None else 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>WND</th>\n",
       "      <th>REM</th>\n",
       "      <th>WND_DIR</th>\n",
       "      <th>WND_SP</th>\n",
       "      <th>TMP</th>\n",
       "      <th>DEW</th>\n",
       "      <th>SLP</th>\n",
       "      <th>VIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72274023160</td>\n",
       "      <td>2012-01-01 00:00:00</td>\n",
       "      <td>999,9,C,0000,5</td>\n",
       "      <td>MET09512/31/11 17:53:03 METAR KTUS 010053Z 000...</td>\n",
       "      <td>000</td>\n",
       "      <td>00</td>\n",
       "      <td>19</td>\n",
       "      <td>01</td>\n",
       "      <td>177</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72274023160</td>\n",
       "      <td>2012-01-01 01:00:00</td>\n",
       "      <td>999,9,C,0000,5</td>\n",
       "      <td>MET09512/31/11 18:53:03 METAR KTUS 010153Z 000...</td>\n",
       "      <td>000</td>\n",
       "      <td>00</td>\n",
       "      <td>16</td>\n",
       "      <td>01</td>\n",
       "      <td>187</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72274023160</td>\n",
       "      <td>2012-01-01 02:00:00</td>\n",
       "      <td>170,5,N,0021,5</td>\n",
       "      <td>MET10112/31/11 19:53:03 METAR KTUS 010253Z 170...</td>\n",
       "      <td>170</td>\n",
       "      <td>04</td>\n",
       "      <td>15</td>\n",
       "      <td>01</td>\n",
       "      <td>194</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72274023160</td>\n",
       "      <td>2012-01-01 03:00:00</td>\n",
       "      <td>999,9,C,0000,5</td>\n",
       "      <td>MET09512/31/11 20:53:03 METAR KTUS 010353Z 000...</td>\n",
       "      <td>000</td>\n",
       "      <td>00</td>\n",
       "      <td>12</td>\n",
       "      <td>02</td>\n",
       "      <td>202</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72274023160</td>\n",
       "      <td>2012-01-01 04:00:00</td>\n",
       "      <td>140,5,N,0021,5</td>\n",
       "      <td>MET09512/31/11 21:53:03 METAR KTUS 010453Z 140...</td>\n",
       "      <td>140</td>\n",
       "      <td>04</td>\n",
       "      <td>11</td>\n",
       "      <td>02</td>\n",
       "      <td>203</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                DATE             WND                                                REM WND_DIR WND_SP TMP DEW  SLP VIS\n",
       "1  72274023160 2012-01-01 00:00:00  999,9,C,0000,5  MET09512/31/11 17:53:03 METAR KTUS 010053Z 000...     000     00  19  01  177  10\n",
       "2  72274023160 2012-01-01 01:00:00  999,9,C,0000,5  MET09512/31/11 18:53:03 METAR KTUS 010153Z 000...     000     00  16  01  187  10\n",
       "3  72274023160 2012-01-01 02:00:00  170,5,N,0021,5  MET10112/31/11 19:53:03 METAR KTUS 010253Z 170...     170     04  15  01  194  10\n",
       "4  72274023160 2012-01-01 03:00:00  999,9,C,0000,5  MET09512/31/11 20:53:03 METAR KTUS 010353Z 000...     000     00  12  02  202  10\n",
       "5  72274023160 2012-01-01 04:00:00  140,5,N,0021,5  MET09512/31/11 21:53:03 METAR KTUS 010453Z 140...     140     04  11  02  203  10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(obs_tables_infos[0].table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>WND</th>\n",
       "      <th>REM</th>\n",
       "      <th>WND_DIR</th>\n",
       "      <th>WND_SP</th>\n",
       "      <th>TMP</th>\n",
       "      <th>DEW</th>\n",
       "      <th>SLP</th>\n",
       "      <th>VIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.2274e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.2274e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.2274e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.2274e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.2274e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.2274e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniques</th>\n",
       "      <td>1</td>\n",
       "      <td>8781</td>\n",
       "      <td>634</td>\n",
       "      <td>9164</td>\n",
       "      <td>38</td>\n",
       "      <td>20</td>\n",
       "      <td>44</td>\n",
       "      <td>25</td>\n",
       "      <td>269</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_perc</th>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>types</th>\n",
       "      <td>constant</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>unique</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 STATION         DATE          WND     REM      WND_DIR       WND_SP          TMP          DEW          SLP          VIS\n",
       "count               9164          NaN          NaN     NaN          NaN          NaN          NaN          NaN          NaN          NaN\n",
       "mean          7.2274e+10          NaN          NaN     NaN          NaN          NaN          NaN          NaN          NaN          NaN\n",
       "std                    0          NaN          NaN     NaN          NaN          NaN          NaN          NaN          NaN          NaN\n",
       "min           7.2274e+10          NaN          NaN     NaN          NaN          NaN          NaN          NaN          NaN          NaN\n",
       "25%           7.2274e+10          NaN          NaN     NaN          NaN          NaN          NaN          NaN          NaN          NaN\n",
       "50%           7.2274e+10          NaN          NaN     NaN          NaN          NaN          NaN          NaN          NaN          NaN\n",
       "75%           7.2274e+10          NaN          NaN     NaN          NaN          NaN          NaN          NaN          NaN          NaN\n",
       "max           7.2274e+10          NaN          NaN     NaN          NaN          NaN          NaN          NaN          NaN          NaN\n",
       "counts              9164         9164         9164    9164         9164         9164         9164         9164         9164         9164\n",
       "uniques                1         8781          634    9164           38           20           44           25          269           11\n",
       "missing                0            0            0       0            0            0            0            0            0            0\n",
       "missing_perc          0%           0%           0%      0%           0%           0%           0%           0%           0%           0%\n",
       "types           constant  categorical  categorical  unique  categorical  categorical  categorical  categorical  categorical  categorical"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(DataFrameSummary(obs_tables_infos[0].table).summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icb1v12 = tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(icb1v12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`join_df` is a function for joining tables on specific fields. By default, we'll be doing a left outer join of `right` on the `left` argument using the given fields for each table.\n",
    "\n",
    "Pandas does joins using the `merge` method. The `suffixes` argument describes the naming convention for duplicate fields. We've elected to leave the duplicate field names on the left untouched, and append a \"\\_y\" to those on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_df(left, right, left_on, right_on=None, suffix='_y'):\n",
    "    if right_on is None: right_on = left_on\n",
    "    return left.merge(right, how='left', left_on=left_on, right_on=right_on, \n",
    "                      suffixes=(\"\", suffix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Cleanup/Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following turns raw year, month and day columns into datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following extracts particular date fields from a complete datetime for the purpose of constructing categoricals.\n",
    "\n",
    "You should *always* consider this feature extraction step when working with date-time. Without expanding your date-time into these additional fields, you can't capture any trend/cyclical behavior as a function of time at any of these granularities. We'll add to every table with a date field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_dates(dataframe=icb1v12, year_field='yrtrig', month_field='motrig', day_field='datrig', \n",
    "              datetime_field='datetime_trig')\n",
    "\n",
    "process_dates(dataframe=icb1v12, year_field='yrterm', month_field='moterm', day_field='daterm', \n",
    "              datetime_field='datetime_term')\n",
    "\n",
    "process_dates(dataframe=icb1v12, year_field='yrmedst', month_field='momedst', day_field='damedst', \n",
    "              datetime_field='datetime_medst')\n",
    "\n",
    "process_dates(dataframe=icb1v12, year_field='yrmedend', month_field='momedend', day_field='damedend', \n",
    "              datetime_field='datetime_medend')\n",
    "\n",
    "process_dates(dataframe=icb1v12, year_field='yrmedfin', month_field='momedfin', day_field='damedfin', \n",
    "              datetime_field='datetime_medfin')\n",
    "\n",
    "display(icb1v12.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop useless generated date columns here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_date_columns = ['datetime_medfinElapsed', 'datetime_medendElapsed', \n",
    "                        'datetime_medstElapsed', 'datetime_termElapsed', 'datetime_trigElapsed']\n",
    "icb1v12.drop(useless_date_columns,1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert booleans to 1s and 0s, so they can be used as categories later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_columns = ['datetime_trigIs_month_end','datetime_trigIs_month_start','datetime_trigIs_quarter_end',\n",
    "            'datetime_trigIs_quarter_start','datetime_trigIs_year_end','datetime_trigIs_year_start',\n",
    "            'datetime_termIs_month_end','datetime_termIs_month_start','datetime_termIs_quarter_end',\n",
    "            'datetime_termIs_quarter_start','datetime_termIs_year_end','datetime_termIs_year_start',\n",
    "            'datetime_medstIs_month_end','datetime_medstIs_month_start','datetime_medstIs_quarter_end',\n",
    "            'datetime_medstIs_quarter_start','datetime_medstIs_year_end','datetime_medstIs_year_start',\n",
    "            'datetime_medendIs_month_end', 'datetime_medendIs_month_start',\n",
    "            'datetime_medendIs_quarter_end','datetime_medendIs_quarter_start','datetime_medendIs_year_end',\n",
    "            'datetime_medendIs_year_start','datetime_medfinIs_month_end',\n",
    "            'datetime_medfinIs_month_start','datetime_medfinIs_quarter_end','datetime_medfinIs_quarter_start',\n",
    "            'datetime_medfinIs_year_end','datetime_medfinIs_year_start']\n",
    "\n",
    "icb1v12[boolean_columns] = (icb1v12[boolean_columns] == True).astype(int)\n",
    "\n",
    "display(icb1v12.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract useful duration information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_duration_from_datetimes(dataframe, begin_field, end_field, duration_field):\n",
    "    dataframe[duration_field] = dataframe[end_field].subtract(dataframe[begin_field]).dt.days\n",
    "    dataframe[duration_field] = np.where(dataframe[duration_field] < 0, 0, dataframe[duration_field]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#TODO:  Should these durations be in days, months, or years?  In the latter two cases, perhaps make it categorical instead of\n",
    "#continuous?\n",
    "\n",
    "#Almost a duplicate of 'brexit', except this version calculates after date data discrepancies are accounted for above.  \n",
    "#I don't think it'll hurt to have both.\n",
    "add_duration_from_datetimes(dataframe=icb1v12, begin_field='datetime_trig', end_field='datetime_term', \n",
    "                            duration_field='event_duration')\n",
    "\n",
    "\n",
    "#TODO:  The code book on mediation dates variables isn't consistent with what's in the CSV.  Which needs to be updated?  \n",
    "#Based on the data, I'm assuming medend == Date of Meditation End Within Crises Period, \n",
    "#and medfin == Date of Meditation End Outside Crises Period\n",
    "\n",
    "add_duration_from_datetimes(dataframe=icb1v12, begin_field='datetime_trig', end_field='datetime_medst', \n",
    "                            duration_field='mediation_start_delay_after_crises_start')\n",
    "\n",
    "\n",
    "add_duration_from_datetimes(dataframe=icb1v12, begin_field='datetime_medst', end_field='datetime_medend', \n",
    "                            duration_field='mediation_duration_within_crisis')\n",
    "\n",
    "add_duration_from_datetimes(dataframe=icb1v12, begin_field='datetime_medend', end_field='datetime_medfin', \n",
    "                            duration_field='mediation_duration_outside')\n",
    "\n",
    "add_duration_from_datetimes(dataframe=icb1v12, begin_field='datetime_medst', end_field='datetime_medfin', \n",
    "                            duration_field='mediation_duration_total')\n",
    "\n",
    "display(icb1v12[icb1v12['mediation_duration_within_crisis'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (TODO) Duration Between World Crises? Use function below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common when working with time series data to extract data that explains relationships across rows as opposed to columns, e.g.:\n",
    "* Running averages\n",
    "* Time until next event\n",
    "* Time since last event\n",
    "\n",
    "This is often difficult to do with most table manipulation frameworks, since they are designed to work with relationships across columns. As such, we've created a class to handle this type of data.\n",
    "\n",
    "We'll define a function `get_elapsed` for cumulative counting across a sorted dataframe. Given a particular field `fld` to monitor, this function will start tracking time since the last occurrence of that field. When the field is seen again, the counter is set to zero.\n",
    "\n",
    "Upon initialization, this will result in datetime na's until the field is encountered. This is reset every time a new store is seen. We'll see how to use this shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elapsed(fld, pre):\n",
    "    day1 = np.timedelta64(1, 'D')\n",
    "    last_date = np.datetime64()\n",
    "    last_store = 0\n",
    "    res = []\n",
    "\n",
    "    for s,v,d in zip(df.Store.values,df[fld].values, df.Date.values):\n",
    "        if s != last_store:\n",
    "            last_date = np.datetime64()\n",
    "            last_store = s\n",
    "        if v: last_date = d\n",
    "        res.append(((d-last_date).astype('timedelta64[D]') / day1))\n",
    "    df[pre+fld] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Known Sources of NaN- Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll fill in missing values to avoid complications with `NA`'s. `NA` (not available) is how Pandas indicates missing values; many models have problems when missing values are present, so it's always important to think about how to deal with them. In these cases, we are picking an arbitrary *signal value* that doesn't otherwise appear in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_to_rows_with_nans(dataframe):\n",
    "    return dataframe[dataframe.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Since we're clasifying escalation/descalation, get rid of category#3 (unknown because of being recent).\n",
    "\n",
    "icb1v12=icb1v12.drop(icb1v12[icb1v12.outesr == 3].index)\n",
    "\n",
    "\n",
    "#This is a weird row- there's no data in it.\n",
    "row_index_to_drop = icb1v12[icb1v12.crisno == 474].index\n",
    "icb1v12=icb1v12.drop(row_index_to_drop)\n",
    "icb1v12.usactor = icb1v12.usactor.fillna(1).astype(np.int32)\n",
    "icb1v12.suinv = icb1v12.suinv.fillna(1).astype(np.int32)\n",
    "icb1v12.suefct = icb1v12.suefct.fillna(1).astype(np.int32)\n",
    "icb1v12.suefac = icb1v12.suefac.fillna(1).astype(np.int32)\n",
    "icb1v12.supace = icb1v12.supace.fillna(1).astype(np.int32)\n",
    "icb1v12.suactor = icb1v12.suactor.fillna(1).astype(np.int32)\n",
    "\n",
    "icb1v12.powdissy = icb1v12.powdissy.fillna(1).astype(np.int32)\n",
    "\n",
    "icb1v12.mediate = icb1v12.mediate.fillna(1).astype(np.int32)\n",
    "icb1v12.mednum = icb1v12.mednum.fillna(1).astype(np.int32)\n",
    "icb1v12.medwho = icb1v12.medwho.fillna(1).astype(np.int32)\n",
    "icb1v12.medtime = icb1v12.medtime.fillna(1).astype(np.int32)\n",
    "icb1v12.medgoal = icb1v12.medgoal.fillna(1).astype(np.int32)\n",
    "icb1v12.medfacl = icb1v12.medfacl.fillna(1).astype(np.int32)\n",
    "icb1v12.medform = icb1v12.medform.fillna(1).astype(np.int32)\n",
    "icb1v12.medmanip = icb1v12.medmanip.fillna(1).astype(np.int32)\n",
    "icb1v12.medstyle = icb1v12.medstyle.fillna(1).astype(np.int32)\n",
    "icb1v12.medstefc = icb1v12.medstefc.fillna(1).astype(np.int32)\n",
    "icb1v12.medefct = icb1v12.medefct.fillna(1).astype(np.int32)\n",
    "icb1v12.medpace = icb1v12.medpace.fillna(1).astype(np.int32)\n",
    "\n",
    "#TODO:  Perhaps default to 0 for dates < 1945, and 1 afterwards? RSO involvement didn't exist prior to that, basically-\n",
    "#source: 1-37 of ICB1Codebook-v12.pdf\n",
    "icb1v12.soract = icb1v12.soract.fillna(1).astype(np.int32)\n",
    "\n",
    "#TODO:  Default on the next two are tough to determine.  \n",
    "icb1v12.hetero = icb1v12.hetero.fillna(1).astype(np.int32)\n",
    "icb1v12.issues = icb1v12.issues.fillna(1).astype(np.int32)\n",
    "\n",
    "icb1v12.chacts = icb1v12.chacts.fillna(1).astype(np.int32)\n",
    "icb1v12.chall = icb1v12.chall.fillna(1).astype(np.int32)\n",
    "icb1v12.powch = icb1v12.powch.fillna(1).astype(np.int32)\n",
    "icb1v12.rugach = icb1v12.rugach.fillna(1).astype(np.int32)\n",
    "\n",
    "icb1v12.usefct = icb1v12.usefct.fillna(1).astype(np.int32)\n",
    "icb1v12.usefac = icb1v12.usefac.fillna(1).astype(np.int32)\n",
    "icb1v12.uspace = icb1v12.uspace.fillna(1).astype(np.int32)\n",
    "\n",
    "#TODO:  Default is tough to determine. \n",
    "icb1v12.stressad = icb1v12.stressad.fillna(1).astype(np.int32)\n",
    "\n",
    "display(filter_to_rows_with_nans(icb1v12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Additional geographic features? Using TRIGENT for triggering entity (country).  Actor level info useful here.  GDP/Per Capita Income/Other measures of wealth?  Government type? Military size?  Climate?  Biggest import/export?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Rolling quanities?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save progress to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's usually a good idea to back up large tables of extracted / wrangled features before you join them onto another one, that way you can go back to it easily if you need to make changes to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icb1v12.reset_index(inplace=True)\n",
    "icb1v12.to_feather(f'{PATH}icb1v12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our final set of engineered features.\n",
    "\n",
    "While these steps were explicitly outlined in the paper, these are all fairly typical feature engineering steps for dealing with time series data and are practical in any similar setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load progress from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icb1v12 = pd.read_feather(f'{PATH}icb1v12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "icb1v12.head().T.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we've engineered all our features, we need to convert to input compatible with a neural network.\n",
    "\n",
    "This includes converting categorical variables into contiguous integers or one-hot encodings, normalizing continuous features to standard normal, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat_vars = ['break','trigent',\n",
    "            #'yrtrig_clean','motrig_clean','datrig_clean','yrterm_clean','moterm_clean','daterm_clean', \n",
    "            'gravcr','crismg','cenviosy','sevviosy','viol','timvio','iwcmb', 'gpinv','gpinvtp','gpefcttp','gpefactp','gppacetp',\n",
    "            'powinv','usinv','usefct','usefac','uspace','usactor','suinv','suefct','suefac','supace','suactor','soglact',\n",
    "            'globorg','globactm','globefct','globefor','globefac','globpace','soract','regorg','regactmb','roefct','robody',\n",
    "            'roefac','ropace','subout','forout','exsat', 'geostr','hetero','issues','chacts','chall','powch','rugach',\n",
    "            'geog','geogrel','period','syslevsy','protrac','ethnic','ethconf', 'sourdt',\n",
    "            #'mediate','mednum','medwho','medtime',\n",
    "            #'yrmedst_clean','momedst_clean','damedst_clean','yrmedend_clean','momedend_clean','damedend_clean',\n",
    "            #'yrmedfin_clean','momedfin_clean', 'damedfin_clean',\n",
    "            #'medgoal','medfacl','medform','medmanip','medstyle',\n",
    "            #'medstefc','medefct','medpace',\n",
    "            'datetime_trigDayofweek',\n",
    "            'datetime_trigIs_month_end','datetime_trigIs_month_start','datetime_trigIs_quarter_end',\n",
    "            #'datetime_trigIs_quarter_start','datetime_trigIs_year_end','datetime_trigIs_year_start',\n",
    "            'datetime_termDayofweek',\n",
    "            #'datetime_termIs_month_end','datetime_termIs_month_start','datetime_termIs_quarter_end',\n",
    "            #'datetime_termIs_quarter_start','datetime_termIs_year_end','datetime_termIs_year_start', \n",
    "            #'datetime_medstDayofweek',\n",
    "            #'datetime_medstIs_month_end','datetime_medstIs_month_start','datetime_medstIs_quarter_end',\n",
    "            #'datetime_medstIs_quarter_start','datetime_medstIs_year_end','datetime_medstIs_year_start',\n",
    "            #'datetime_medendDayofweek','datetime_medendIs_month_end', 'datetime_medendIs_month_start',\n",
    "            #'datetime_medendIs_quarter_end','datetime_medendIs_quarter_start','datetime_medendIs_year_end',\n",
    "            #'datetime_medendIs_year_start','datetime_medfinDayofweek', 'datetime_medfinIs_month_end',\n",
    "            #'datetime_medfinIs_month_start','datetime_medfinIs_quarter_end','datetime_medfinIs_quarter_start',\n",
    "            #'datetime_medfinIs_year_end','datetime_medfinIs_year_start'\n",
    "]\n",
    "\n",
    "contin_vars = [\n",
    "        'brexit','noactr','cractr', 'pcid', 'powdissy', 'stressad', 'event_duration',\n",
    "        #'mediation_start_delay_after_crises_start',\n",
    "        #'mediation_duration_within_crisis','mediation_duration_outside',\n",
    "        #'mediation_duration_total'\n",
    "]\n",
    "\n",
    "n = len(icb1v12); n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dep = 'outesr'\n",
    "icb1v12 = icb1v12[cat_vars+contin_vars+[dep, 'datetime_trig']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#TODO:  Not sure if this is the best default\n",
    "icb1v12[dep] = icb1v12[dep].fillna(3).astype(np.int32)\n",
    "icb1v12[dep] = icb1v12[dep]-1\n",
    "\n",
    "for v in cat_vars:\n",
    "    icb1v12[v] = icb1v12[v].astype('category').cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "apply_cats(icb1v12.copy(), icb1v12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for v in contin_vars:\n",
    "    icb1v12[v] = icb1v12[v].fillna(0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "icb1v12.set_index(\"datetime_trig\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can now process our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "icb1v12.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df, y, nas, mapper = proc_df(icb1v12, dep, do_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In time series data, cross-validation is not random. Instead, our holdout data is generally the most recent data, as it would be in real application. This issue is discussed in detail in [this post](http://www.fast.ai/2017/11/13/validation-sets/) on our web site.\n",
    "\n",
    "One approach is to take the last 25% of rows (sorted by date) as our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "train_size = int(n * train_ratio); train_size\n",
    "val_idx = list(range(train_size, len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to put together our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a ModelData object directly from out data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_data_frame(PATH, val_idx, df, y.astype('int'), cat_flds=cat_vars, bs=8,test_df=None, \n",
    "                                       is_reg=False,is_multi=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some categorical variables have a lot more levels than others. Store, in particular, has over a thousand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sz = [(c, len(icb1v12[c].cat.categories)+1) for c in cat_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the *cardinality* of each variable (that is, its number of unique values) to decide how large to make its *embeddings*. Each level will be associated with a vector with length defined as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = [(c, min(50, (c+1)//2)) for _,c in cat_sz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = md.get_learner(emb_szs, n_cont=len(df.columns)-len(cat_vars),\n",
    "        emb_drop=0.05, out_sz=3, szs=[1000,500], drops=[0.001,0.01],y_range=[0,1],\n",
    "        use_bn=True, crit=F.cross_entropy)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "m.fit(lr, n_cycle=3, metrics=[accuracy], cycle_len=1, cycle_mult=2, wds=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "173px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
