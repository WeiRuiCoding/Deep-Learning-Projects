{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from torch import autograd\n",
    "from fastai.conv_learner import *\n",
    "from fastai.transforms import TfmType\n",
    "from fasterai.transforms import *\n",
    "from fasterai.images import *\n",
    "from fasterai.dataset import *\n",
    "from fasterai.visualize import *\n",
    "from fasterai.callbacks import *\n",
    "from fasterai.loss import *\n",
    "from fasterai.modules import *\n",
    "from fasterai.wgan import *\n",
    "from fasterai.generators import *\n",
    "from fastai.torch_imports import *\n",
    "from pathlib import Path\n",
    "from itertools import repeat\n",
    "import tensorboardX\n",
    "torch.cuda.set_device(1)\n",
    "plt.style.use('dark_background')\n",
    "torch.backends.cudnn.benchmark=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST NOTES:  Replacing batchnorm with instance norm; Adding \"shock absorbing\" training sessions between size changes.\n",
    "IMAGENET = Path('data/imagenet/ILSVRC/Data/CLS-LOC/train')\n",
    "OPENIMAGES = Path('data/openimages')\n",
    "CIFAR10 = Path('data/cifar10/train')\n",
    "\n",
    "proj_id = 'super_res'\n",
    "TENSORBOARD_PATH = Path('data/tensorboard/' + proj_id)\n",
    "\n",
    "#gpath = IMAGENET.parent/('bwc_withattn_sn_supertrain2x_gen_96.h5')\n",
    "#dpath = IMAGENET.parent/('bwc_withattn_sn_supertrain2x_critic_96.h5')\n",
    "\n",
    "c_lr=1e-3\n",
    "c_lrs = np.array([c_lr,c_lr,c_lr])\n",
    "\n",
    "g_lr=c_lr/5\n",
    "g_lrs = np.array([g_lr/100,g_lr/10,g_lr])\n",
    "\n",
    "keep_pcts=[0.20,0.20]\n",
    "gen_freeze_tos=[-1,0]\n",
    "\n",
    "scale=2\n",
    "sn=True\n",
    "self_attention=sn\n",
    "lrs_unfreeze_factor=0.25\n",
    "x_tfms=[]\n",
    "extra_aug_tfms=[]\n",
    "\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Unet34(nf_factor=1, self_attention=self_attention, sn=sn, leakyReLu=False, scale=scale).cuda()\n",
    "#netGVis = ModelVisualizationHook(TENSORBOARD_PATH, netG, 'netG')\n",
    "#load_model(netG, gpath)\n",
    "\n",
    "netD = DCCritic(ni=3, nf=128, scale=16, self_attention=self_attention, sn=sn).cuda()\n",
    "#netDVis = ModelVisualizationHook(TENSORBOARD_PATH, netD, 'netD')\n",
    "#load_model(netD, dpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = WGANTrainer(netD=netD, netG=netG, genloss_fns=[FeatureLoss(multiplier=1e2)], sn=sn)\n",
    "trainerVis = WganVisualizationHook(TENSORBOARD_PATH, trainer, 'trainer', jupyter=False, visual_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheds=[]\n",
    "\n",
    "scheds.extend(WGANTrainSchedule.generate_schedules(szs=[128,128], bss=[32,32], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=keep_pcts, \n",
    "    save_base_name=proj_id, c_lrs=c_lrs, g_lrs=g_lrs, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=gen_freeze_tos, reduce_x_scale=scale))\n",
    "\n",
    "scheds.extend(WGANTrainSchedule.generate_schedules(szs=[128,128], bss=[32,32], path=OPENIMAGES, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.3,0.3], \n",
    "    save_base_name=proj_id, c_lrs=c_lrs, g_lrs=g_lrs, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=gen_freeze_tos, reduce_x_scale=scale))\n",
    "\n",
    "\n",
    "\n",
    "#unshock\n",
    "scheds.extend(WGANTrainSchedule.generate_schedules(szs=[192], bss=[16], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.1], \n",
    "    save_base_name=proj_id, c_lrs=c_lrs/20, g_lrs=g_lrs/20, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[-1], reduce_x_scale=scale))\n",
    "\n",
    "scheds.extend(WGANTrainSchedule.generate_schedules(szs=[192], bss=[16], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.2], \n",
    "    save_base_name=proj_id, c_lrs=c_lrs/2, g_lrs=g_lrs/2, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[-1], reduce_x_scale=scale))\n",
    "\n",
    "scheds.extend(WGANTrainSchedule.generate_schedules(szs=[192], bss=[16], path=OPENIMAGES, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.3], \n",
    "    save_base_name=proj_id, c_lrs=c_lrs/2, g_lrs=g_lrs/2, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[-1], reduce_x_scale=scale))\n",
    "\n",
    "scheds.extend(WGANTrainSchedule.generate_schedules(szs=[192], bss=[16], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.2], \n",
    "    save_base_name=proj_id, c_lrs=c_lrs/6, g_lrs=g_lrs/6, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[0], reduce_x_scale=scale))\n",
    "\n",
    "scheds.extend(WGANTrainSchedule.generate_schedules(szs=[192], bss=[16], path=OPENIMAGES, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.3], \n",
    "    save_base_name=proj_id, c_lrs=c_lrs/6, g_lrs=g_lrs/6, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[0], reduce_x_scale=scale))\n",
    "\n",
    "\n",
    "#unshock\n",
    "scheds.extend(WGANTrainSchedule.generate_schedules(szs=[256], bss=[8], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.1], \n",
    "    save_base_name=proj_id, c_lrs=c_lrs/120, g_lrs=g_lrs/120, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[-1], reduce_x_scale=scale))\n",
    "\n",
    "scheds.extend(WGANTrainSchedule.generate_schedules(szs=[256], bss=[8], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.2], \n",
    "    save_base_name=proj_id, c_lrs=c_lrs/12, g_lrs=g_lrs/12, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[-1], reduce_x_scale=scale))\n",
    "\n",
    "scheds.extend(WGANTrainSchedule.generate_schedules(szs=[256], bss=[8], path=OPENIMAGES, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.3], \n",
    "    save_base_name=proj_id, c_lrs=c_lrs/12, g_lrs=g_lrs/12, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[-1], reduce_x_scale=scale))\n",
    "\n",
    "scheds.extend(WGANTrainSchedule.generate_schedules(szs=[256], bss=[8], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.2], \n",
    "    save_base_name=proj_id, c_lrs=c_lrs/24, g_lrs=g_lrs/24, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[0], reduce_x_scale=scale))\n",
    "\n",
    "scheds.extend(WGANTrainSchedule.generate_schedules(szs=[256], bss=[8], path=OPENIMAGES, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.3], \n",
    "    save_base_name=proj_id, c_lrs=c_lrs/24, g_lrs=g_lrs/24, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[0], reduce_x_scale=scale))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/onnx/symbolic.py:130: UserWarning: ONNX export failed on dim because ONNX and PyTorch use different strategies to split the input. not supported\n",
      "  warnings.warn(\"ONNX export failed on \" + op + \" because \" + msg + \" not supported\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate graph for model: %43 : Long() = onnx::Constant[value={0}]()\n",
      " has empty scope name. Note that there's an outstanding issue with scopes being addressed here:  https://github.com/pytorch/pytorch/pull/12400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/jason/Projects/Deep Learning/Deep Learning Projects/super resolution/fasterai/generators.py:161: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if h<target_h or w<target_w:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate graph for model: %479 : Long() = onnx::Constant[value={2}]()\n",
      " has empty scope name. Note that there's an outstanding issue with scopes being addressed here:  https://github.com/pytorch/pytorch/pull/12400\n",
      "  0%|          | 0/7627 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/onnx/symbolic.py:130: UserWarning: ONNX export failed on dim because ONNX and PyTorch use different strategies to split the input. not supported\n",
      "  warnings.warn(\"ONNX export failed on \" + op + \" because \" + msg + \" not supported\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/7627 [00:29<1:47:17,  1.18it/s]\n",
      "WDist 1.8324944972991943; RScore 1.2281556129455566; FScore 0.6043388843536377; GAddlLoss [7.97772]; Iters: 10; GCost: 2.2304227352142334; GPenalty: [0]; ConPenalty: [0]\n",
      "  1%|          | 40/7627 [00:41<54:57,  2.30it/s]  \n",
      "WDist 1.8389149904251099; RScore 1.771890640258789; FScore 0.06702432036399841; GAddlLoss [7.09086]; Iters: 20; GCost: -0.031806934624910355; GPenalty: [0]; ConPenalty: [0]\n",
      "  1%|          | 60/7627 [00:56<43:00,  2.93it/s]\n",
      "WDist 1.6337389945983887; RScore 0.6577204465866089; FScore 0.9760186076164246; GAddlLoss [6.93698]; Iters: 30; GCost: 0.15023335814476013; GPenalty: [0]; ConPenalty: [0]\n",
      "  1%|          | 80/7627 [01:11<37:48,  3.33it/s]\n",
      "WDist 1.6346361637115479; RScore 0.4791252017021179; FScore 1.1555110216140747; GAddlLoss [6.57196]; Iters: 40; GCost: 0.040726568549871445; GPenalty: [0]; ConPenalty: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(scheds=scheds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
