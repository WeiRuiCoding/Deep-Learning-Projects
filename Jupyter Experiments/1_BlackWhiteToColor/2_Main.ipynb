{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black and White to Color Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from fastai.conv_learner import *\n",
    "from pathlib import Path\n",
    "from itertools import repeat\n",
    "plt.style.use('dark_background')\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/imagenet/ILSVRC/Data/CLS-LOC')\n",
    "PATH_TRN = PATH/'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_resized = PATH/('train_' + str(sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_resized_bw = PATH/('train_' + str(sz) + '_bw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dest_path(sourceroot: Path, sourcepath: Path, destroot: Path):\n",
    "    relativepath = sourcepath.relative_to(sourceroot)\n",
    "    destpath = destroot/relativepath\n",
    "    return destpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dest_path_generator(sourceroot: Path, raw_sourcepaths: [Path], destroot: Path):\n",
    "    return (generate_dest_path(sourceroot=sourceroot, sourcepath=sourceroot.parent/Path(raw_sourcepath), destroot=destroot) for raw_sourcepath in raw_sourcepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_folders_for_dest(destpaths: [Path]):\n",
    "    destdirs = set(destpath.parent for destpath in destpaths)\n",
    "    \n",
    "    for destdir in destdirs:\n",
    "        destdir.mkdir(parents=True, exist_ok=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image_and_save_new(function, sourcepath: Path, destpath: Path):\n",
    "    try:\n",
    "        with Image.open(sourcepath) as image:\n",
    "            image = function(image)\n",
    "            image.save(destpath)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_images_to_new_directory(function, sourceroot: Path, destroot: Path):\n",
    "    destroot.mkdir(exist_ok=True)\n",
    "    raw_sourcepaths, _, _ = folder_source(sourceroot.parent, sourceroot.name)\n",
    "    #First make the destination directories if they don't already exist- we want the subsequent operations to be threadsafe.  Then create\n",
    "    #another generator of destpaths for use in the image generation\n",
    "    generate_folders_for_dest(destpaths=dest_path_generator(sourceroot=sourceroot, raw_sourcepaths=raw_sourcepaths, destroot=destroot))   \n",
    "    destpaths = dest_path_generator(sourceroot=sourceroot, raw_sourcepaths=raw_sourcepaths, destroot=destroot)\n",
    "    sourcepaths = (sourceroot.parent/Path(raw_sourcepath) for raw_sourcepath in raw_sourcepaths)\n",
    "    numthreads = multiprocessing.cpu_count()\n",
    "    \n",
    "    with ThreadPoolExecutor(numthreads) as e:\n",
    "        try:\n",
    "            e.map(partial(transform_image_and_save_new, function), sourcepaths, destpaths)\n",
    "        except Exception as ex:\n",
    "            print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image: Image, size: int):\n",
    "    return image.resize((size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 19660800 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18481152 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 37093376 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 39976960 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 34865152 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
      "  warnings.warn(str(msg))\n",
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot write mode RGBA as JPEG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2555904 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:739: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1835008 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/jason/anaconda3/envs/fastai/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "transform_images_to_new_directory(partial(resize_image, size=sz), PATH_TRN, train_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Black and White Versions of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grayscale_image(image: Image):\n",
    "    return image.convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_images_to_new_directory(to_grayscale_image, train_resized, train_resized_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_full_x,label_arr_full_x,all_labels_x = folder_source(train_resized_bw.parent, train_resized_bw.name)\n",
    "fnames_full_x = ['/'.join(Path(fn).parts[-2:]) for fn in fnames_full_x]\n",
    "list(zip(fnames_full_x[:5],label_arr_full_x[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_full_y,label_arr_full_y,all_labels_y = folder_source(train_resized.parent, train_resized.name)\n",
    "fnames_full_y = ['/'.join(Path(fn).parts[-2:]) for fn in fnames_full_y]\n",
    "list(zip(fnames_full_y[:5],label_arr_full_y[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "np.random.seed(42)\n",
    "#keep_pct = 1.\n",
    "keep_pct = 0.02\n",
    "keeps = np.random.rand(len(fnames_full_x)) < keep_pct\n",
    "fnames_x = np.array(fnames_full_x, copy=False)[keeps]\n",
    "label_arr_x = np.array(label_arr_full_x, copy=False)[keeps]\n",
    "fnames_y = np.array(fnames_full_y, copy=False)[keeps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchedFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames_x, fnames_y, transform, path):\n",
    "        self.y=fnames_y\n",
    "        assert(len(fnames_x)==len(fnames_y))\n",
    "        super().__init__(fnames_x, transform, path)\n",
    "    def get_y(self, i): \n",
    "        return open_image(os.path.join(self.path, self.y[i]))\n",
    "    def get_c(self): return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_tfms = [RandomDihedral(tfm_y=TfmType.PIXEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idxs = get_cv_idxs(len(fnames_x), val_pct=min(0.01/keep_pct, 0.1))\n",
    "((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, np.array(fnames_x), np.array(fnames_y))\n",
    "len(val_x),len(trn_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fn = train_resized_bw/'n01558993'/'n01558993_9684.JPEG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(arch, sz, tfm_y=TfmType.PIXEL, aug_tfms=aug_tfms, sz_y=sz)\n",
    "datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), (val_x,val_y), tfms, path=train_resized_bw.parent)\n",
    "md = ImageData(PATH, datasets, bs, num_workers=16, classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denorm = md.val_ds.denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(ims, idx, figsize=(5,5), normed=True, ax=None):\n",
    "    if ax is None: fig,ax = plt.subplots(figsize=figsize)\n",
    "    if normed: ims = denorm(ims)\n",
    "    else:      ims = np.rollaxis(to_np(ims),1,4)\n",
    "    ax.imshow(np.clip(ims,0,1)[idx])\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "x.size(),y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=1\n",
    "fig,axes = plt.subplots(1, 2, figsize=(9,5))\n",
    "show_img(x,idx, ax=axes[0])\n",
    "show_img(y,idx, ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [next(iter(md.aug_dl)) for i in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 6, figsize=(18, 9))\n",
    "for i,(x,y) in enumerate(batches):\n",
    "    show_img(x,idx, ax=axes.flat[i*2])\n",
    "    show_img(y,idx, ax=axes.flat[i*2+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(ni, nf, kernel_size=3, actn=False):\n",
    "    layers = [nn.Conv2d(ni, nf, kernel_size, padding=kernel_size//2)]\n",
    "    if actn: layers.append(nn.ReLU(True))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResSequential(nn.Module):\n",
    "    def __init__(self, layers, res_scale=1.0):\n",
    "        super().__init__()\n",
    "        self.res_scale = res_scale\n",
    "        self.m = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return x + self.m(x) * self.res_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(nf):\n",
    "    return ResSequential(\n",
    "        [conv(nf, nf, actn=True), conv(nf, nf)],\n",
    "        0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(ni, nf, scale):\n",
    "    layers = []\n",
    "    for i in range(int(math.log(scale,2))):\n",
    "        layers += [conv(ni, nf*(scale**2)), nn.PixelShuffle(2)]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SrResnet(nn.Module):\n",
    "    def __init__(self, nf, scale):\n",
    "        super().__init__()\n",
    "        features = [conv(3, 64)]\n",
    "        for i in range(8): features.append(res_block(64))\n",
    "        features += [conv(64,64), upsample(64, 64, scale),\n",
    "                     nn.BatchNorm2d(64),\n",
    "                     conv(64, 3)]\n",
    "        self.features = nn.Sequential(*features)\n",
    "        \n",
    "    def forward(self, x): return self.features(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icnr(x, scale=2, init=nn.init.kaiming_normal):\n",
    "    new_shape = [int(x.shape[0] / (scale ** 2))] + list(x.shape[1:])\n",
    "    subkernel = torch.zeros(new_shape)\n",
    "    subkernel = init(subkernel)\n",
    "    subkernel = subkernel.transpose(0, 1)\n",
    "    subkernel = subkernel.contiguous().view(subkernel.shape[0],\n",
    "                                            subkernel.shape[1], -1)\n",
    "    kernel = subkernel.repeat(1, 1, scale ** 2)\n",
    "    transposed_shape = [x.shape[1]] + [x.shape[0]] + list(x.shape[2:])\n",
    "    kernel = kernel.contiguous().view(transposed_shape)\n",
    "    kernel = kernel.transpose(0, 1)\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_vgg = vgg16(True)\n",
    "\n",
    "blocks = [i-1 for i,o in enumerate(children(m_vgg))\n",
    "              if isinstance(o,nn.MaxPool2d)]\n",
    "blocks, [m_vgg[i] for i in blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_layers = children(m_vgg)[:23]\n",
    "m_vgg = nn.Sequential(*vgg_layers).cuda().eval()\n",
    "set_trainable(m_vgg, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x): return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m,self.wgts = m,layer_wgts\n",
    "        self.sfs = [SaveFeatures(m[i]) for i in layer_ids]\n",
    "\n",
    "    def forward(self, input, target, sum_layers=True):\n",
    "        self.m(VV(target.data))\n",
    "        res = [F.l1_loss(input,target)/100]\n",
    "        targ_feat = [V(o.features.data.clone()) for o in self.sfs]\n",
    "        self.m(input)\n",
    "        res += [F.l1_loss(flatten(inp.features),flatten(targ))*wgt\n",
    "               for inp,targ,wgt in zip(self.sfs, targ_feat, self.wgts)]\n",
    "        if sum_layers: res = sum(res)\n",
    "        return res\n",
    "    \n",
    "    def close(self):\n",
    "        for o in self.sfs: o.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SrResnet(64, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_shuffle = m.features[10][0][0]\n",
    "kernel = icnr(conv_shuffle.weight, scale=scale)\n",
    "conv_shuffle.weight.data.copy_(kernel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = to_gpu(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(md, SingleModel(m), opt_fn=optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.DataParallel(m, [0,1,2,3])\n",
    "learn = Learner(md, SingleModel(m), opt_fn=optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.set_data(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.crit = FeatureLoss(m_vgg, blocks[:3], [0.2,0.7,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(1e-4, 0.1, wds=wd, linear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot(n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3\n",
    "wd=1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=2, wds=wd, use_clr_beta=(20,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('bwtoc0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bwtoc0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=lr/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=1, wds=wd, use_clr_beta=(20,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('bwtoc1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bwtoc1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr/3, 1, cycle_len=1, wds=wd, use_clr_beta=(20,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('bwtoc2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bwtoc2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ds_img(idx, ax=None, figsize=(7,7), normed=True):\n",
    "    if ax is None: fig,ax = plt.subplots(figsize=figsize)\n",
    "    im = md.val_ds[idx][0]\n",
    "    if normed: im = denorm(im)[0]\n",
    "    else:      im = np.rollaxis(to_np(im),0,3)\n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(6,6,figsize=(20,20))\n",
    "for i,ax in enumerate(axes.flat): plot_ds_img(i+200,ax=ax, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x,y=md.val_ds[211]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval()\n",
    "preds = learn.model(VV(x[None]))\n",
    "x.shape,y.shape,preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.crit(preds, V(y), sum_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_,axes=plt.subplots(1,2,figsize=(14,7))\n",
    "show_img(x[None], 0, ax=axes[0])\n",
    "show_img(preds,0, normed=True, ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "sz = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.load(learn.get_model_path('bwtoc2'), map_location=lambda storage, loc: storage)\n",
    "learn.model.load_state_dict(t, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,13): set_trainable(learn.model.module.features[i], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_shuffle = learn.model.module.features[10][2][0]\n",
    "kernel = icnr(conv_shuffle.weight, scale=scale)\n",
    "conv_shuffle.weight.data.copy_(kernel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=6e-3\n",
    "wd=1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=2, wds=wd, use_clr_beta=(20,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('bwtoc3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bwtoc3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr/2, 1, cycle_len=2, wds=wd, use_clr_beta=(20,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('bwtoc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bwtoc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr/6, 1, cycle_len=1, wds=wd, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('bwtoc5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('bwtoc5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms,val_tfms = tfms_from_model(arch, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = 'data/style/'\n",
    "image_name = 'csi_enhance'\n",
    "img_fn = f'{image_root}{image_name}.jpg'\n",
    "img = open_image(img_fn)\n",
    "img_tfm = val_tfms(img)\n",
    "preds = learn.model(VV(img_tfm[None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes=plt.subplots(1,2,figsize=(14,7))\n",
    "show_img(img_tfm[None], 0, ax=axes[0])\n",
    "show_img(preds,0, normed=True, ax=axes[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
